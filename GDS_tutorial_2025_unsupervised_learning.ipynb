{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mwVbVZAq14yv"
   },
   "source": [
    "# **GDS Short Course on Data Science for Physicists I**\n",
    "# Unsupervised learning tutorial\n",
    "Trevor David Rhone\n",
    "- Rensselaer Polytechnic Institute\n",
    "- https://materials-intelligence.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AQuH-LcayMC_"
   },
   "source": [
    "Preliminary activities:\n",
    "- switch to a gpu runtime type\n",
    "- install the packages below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](\n",
    "https://colab.research.google.com/github/quantum-intelligence/materials-informatics-tutorial/blob/main/GDS_tutorial_2025_unsupervised_learning.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B58cTAL1yUUc",
    "outputId": "7f41e372-ffb8-4847-c3e0-4f8cced4e1d1"
   },
   "outputs": [],
   "source": [
    "!pip install pymatgen pandas tensorflow keras numpy scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T_vVQisX1XwJ"
   },
   "outputs": [],
   "source": [
    "# import useful python modules\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xBs-T1GwTS6u"
   },
   "source": [
    "#K-means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rP6hWwX62ug0"
   },
   "outputs": [],
   "source": [
    "# import useful modeules\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "# Generate dummy data with 3 clusters using make_blobs()\n",
    "n_samples = 300\n",
    "n_features = 2\n",
    "n_clusters = 3\n",
    "random_state = 42\n",
    "\n",
    "X, _ = make_blobs(n_samples=n_samples, n_features=n_features, centers=n_clusters, random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "acItxuUL21lr"
   },
   "source": [
    "Inspecct the contents of X, its shape, print a few values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tk547fEc20Pv"
   },
   "outputs": [],
   "source": [
    "# Enter your code here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "JkXLdfCkDWAm",
    "outputId": "23f8319d-8fef-4a34-88d9-53e665a507a1"
   },
   "outputs": [],
   "source": [
    "# Perform K-Means clustering\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=random_state, n_init=10)\n",
    "kmeans.fit(X)\n",
    "y_pred = kmeans.labels_\n",
    "\n",
    "# Plot the clusters\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y_pred, cmap='viridis', edgecolors='k', alpha=0.6)\n",
    "plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1],\n",
    "            s=200, c='red', marker='X', edgecolors='black', label=\"Centroids\")\n",
    "\n",
    "plt.title(\"K-Means Clustering on Dummy Data\")\n",
    "plt.xlabel(\"Feature 1\")\n",
    "plt.ylabel(\"Feature 2\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KvBBVPqDO7fD"
   },
   "source": [
    "### Question:\n",
    "- Change n_cluster, n_features and re run the code above.  How do we know to set K for an 'unknown' data set?\n",
    "- How can K-means clustering be applied to learn patterns in 'real world' data?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lUpdTWHHU7LV"
   },
   "source": [
    "# Principal components analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p4L-xsKt33Rw"
   },
   "outputs": [],
   "source": [
    "# import useful modules\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Generate high-dimensional dummy data (10 features) using sklearn.datasets.make_classification()\n",
    "n_samples = 300\n",
    "n_features = 10\n",
    "n_classes = 3\n",
    "random_state = 42\n",
    "\n",
    "X, y = make_classification(n_samples=n_samples, n_features=n_features,\n",
    "                           n_informative=5, n_clusters_per_class=1,\n",
    "                           n_classes=n_classes, random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m-edqbsW34Is"
   },
   "source": [
    "Inspect the contents of X:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6-9prSf635ZJ"
   },
   "outputs": [],
   "source": [
    "# Write your code here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 503
    },
    "id": "_WsJLjPTU8sX",
    "outputId": "153b38e8-7026-4a67-a74c-880d80c0b15c"
   },
   "outputs": [],
   "source": [
    "# Standardize the features (PCA works better with normalized data)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Apply PCA to reduce to 2 dimensions\n",
    "pca = PCA(n_components=3)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "plt.subplot(2,1,1)\n",
    "# Plot the PCA-transformed data\n",
    "# plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y, cmap='viridis', edgecolors='k', alpha=0.7)\n",
    "plt.xlabel(\"Principal Component 1\")\n",
    "plt.ylabel(\"Principal Component 2\")\n",
    "plt.title(\"PCA Visualization of High-Dimensional Data\")\n",
    "plt.colorbar(label=\"Class Label\")\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "# Plot the PCA-transformed data\n",
    "# plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X_pca[:, 0], X_pca[:, 2], c=y, cmap='viridis', edgecolors='k', alpha=0.7)\n",
    "plt.xlabel(\"Principal Component 1\")\n",
    "plt.ylabel(\"Principal Component 3\")\n",
    "plt.title(\"PCA Visualization of High-Dimensional Data\")\n",
    "plt.colorbar(label=\"Class Label\")\n",
    "plt.grid(True)\n",
    "\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print explained variance ratio\n",
    "print(f\"Explained variance by PC1 & PC2: {pca.explained_variance_ratio_.sum():.2%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "18YGlBKQP75a"
   },
   "source": [
    "### Question:\n",
    "- How can PCA be applied to learn patterns in 'real world' data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KwvrTr1XVnX2"
   },
   "source": [
    "## Access Materials Project\n",
    "- create an account with the materials project\n",
    "- input your API_KEY below:\n",
    "- Are you using the modern or legacy API?\n",
    " - https://docs.materialsproject.org/downloading-data/differences-between-new-and-legacy-api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MD64gouqCQak",
    "outputId": "5e71abd4-3e75-4d39-e4ba-3357d2af5b36"
   },
   "outputs": [],
   "source": [
    "!pip install mp-api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UrWnHOupVzXe"
   },
   "outputs": [],
   "source": [
    "use_legacy_materials_project = False\n",
    "if use_legacy_materials_project:\n",
    "  from pymatgen.ext.matproj import MPRester\n",
    "  # Replace with your Materials Project API key\n",
    "  API_KEY = \"insert your key here\" #replace with your key\n",
    "  mpr = MPRester(API_KEY)\n",
    "else:\n",
    "  from mp_api.client import MPRester\n",
    "  # Replace with your Materials Project API key\n",
    "  API_KEY = \"insert your key here\" #replace with your key\n",
    "  mpr = MPRester(API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iDXA59TiDYhX"
   },
   "source": [
    "#Associative learning\n",
    "- The cell below pulls data from the materials project (https://next-gen.materialsproject.org/)\n",
    "- You will need an account and an API key to use this free service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JvWDLCzLVdB6"
   },
   "source": [
    "### Download data from the materials project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "a1e3b119525149b5875e5a8eaf1228c7",
      "e1a173b6cfe64f4d9d3d25c8391081ef",
      "160771ba62024561b172126a87c85e7e",
      "7c92e826aad645c1bba4daca3ec75e80",
      "49c0e9f9252a45e59afcf8fc4aaa7eb9",
      "a6c19dcedf68401d9cd274570aadee8b",
      "d8373e2b262e405f89f7da81231c3f95",
      "c5f09842bd26455a9c4aef70b322d6b0",
      "a80e062510ec4dd79efda9415b94d019",
      "ccd8ede310584d0393907e72c96f388d",
      "7ae52f5fe91f44d58448b47226541404"
     ]
    },
    "id": "cRaIIKYeDV5X",
    "outputId": "6a24afab-ea0f-40e8-ff3a-3944dbb19894"
   },
   "outputs": [],
   "source": [
    "# import useful modules\n",
    "import pandas as pd\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "\n",
    "# Query oxide materials with band gap data and formation energy per atom data\n",
    "if use_legacy_materials_project:\n",
    "  materials_data = mpr.query(\n",
    "      {\"elements\": {\"$in\": [\"O\",\"Se\",\"Te\"]}, \"band_gap\": {\"$gt\": 0}},  # Select materials containing oxygen & nonzero band gap\n",
    "      [\"task_id\", \"pretty_formula\", \"elements\", \"band_gap\", \"e_above_hull\", \"formation_energy_per_atom\"]\n",
    "  )\n",
    "else:\n",
    "  with MPRester(API_KEY) as mpr:\n",
    "    materials_data = mpr.materials.summary.search(\n",
    "        elements=[\"Si\", \"O\"], band_gap=(0.0, None),\n",
    "        fields=[\"material_id\", \"formula_pretty\", \"elements\", \"band_gap\", \"energy_above_hull\", \"formation_energy_per_atom\"]\n",
    "    )\n",
    "# you can pickle the result and save to your google drive to reload data with ease.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VMIocsPLVmex"
   },
   "source": [
    "### Data wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KlCSwZONFwJB"
   },
   "outputs": [],
   "source": [
    "# Flatten nested data within each document\n",
    "def flatten_dict(d, parent_key='', sep='_'):\n",
    "    items = []\n",
    "    for k, v in d.items():\n",
    "        new_key = parent_key + sep + k if parent_key else k\n",
    "        if isinstance(v, dict):\n",
    "            items.extend(flatten_dict(v, new_key, sep=sep).items())\n",
    "        else:\n",
    "            items.append((new_key, v))\n",
    "    return dict(items)\n",
    "\n",
    "\n",
    "if use_legacy_materials_project:\n",
    "  # Convert to DataFrame\n",
    "  df = pd.DataFrame(materials_data)\n",
    "else:\n",
    "  # Flatten each document before creating the DataFrame\n",
    "  flattened_docs = [flatten_dict(doc.dict()) for doc in materials_data]\n",
    "  df = pd.DataFrame(flattened_docs)\n",
    "  df_clean = df.dropna(axis=1)\n",
    "  df_clean = df_clean.drop(columns=\"fields_not_requested\")\n",
    "  df = df_clean.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "QczQy7YC1lWf",
    "outputId": "4492e0b0-0020-4e8d-b860-74dea8e01fd7"
   },
   "outputs": [],
   "source": [
    "# inspect database\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "me-Xeduy-kNv"
   },
   "outputs": [],
   "source": [
    "# Define band gap categories\n",
    "def categorize_band_gap(bg):\n",
    "    if bg < 1:\n",
    "        return \"Low Band Gap\"\n",
    "    elif 1 <= bg < 3:\n",
    "        return \"Medium Band Gap\"\n",
    "    else:\n",
    "        return \"High Band Gap\"\n",
    "\n",
    "# Define formation energy categories\n",
    "def categorize_formation_energy(ef):\n",
    "    if ef > -1.0:\n",
    "        return \"Low stability\"\n",
    "    elif -3.0 < ef <= -1.0:\n",
    "        return \"Medium stability\"\n",
    "    else:\n",
    "        return \"High stability\"\n",
    "# Apply categorization\n",
    "\n",
    "use_formation_energy = True\n",
    "if use_formation_energy:\n",
    "  df[\"Formation Energy Category\"] = df[\"formation_energy_per_atom\"].apply(categorize_formation_energy)\n",
    "else:\n",
    "  # use the band gap info\n",
    "  df[\"Band Gap Category\"] = df[\"band_gap\"].apply(categorize_band_gap)\n",
    "\n",
    "# One-hot encode elements\n",
    "unique_elements = set(el for elems in df[\"elements\"] for el in elems)\n",
    "for element in unique_elements:\n",
    "    df[element] = df[\"elements\"].apply(lambda x: 1 if element in x else 0)\n",
    "\n",
    "# One-hot encode band gap categories\n",
    "if use_formation_energy:\n",
    "  df = pd.get_dummies(df, columns=[\"Formation Energy Category\"])\n",
    "else:\n",
    "  df = pd.get_dummies(df, columns=[\"Band Gap Category\"])\n",
    "\n",
    "df_mp = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k1mAbrxrW0MC"
   },
   "source": [
    "### inspect data downloaded from the materials project\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 342
    },
    "id": "zA4oJEvhAyEL",
    "outputId": "c652b15b-b228-4653-cfe7-3f9e367bab98"
   },
   "outputs": [],
   "source": [
    "# inspect data downloaded from the materials project\n",
    "print(\"Number of data entries from the materials project: \", df_mp.shape[0])\n",
    "print(\"Number of data attributes: \", df_mp.shape[1])\n",
    "df_mp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "_YKWUG7zBTcX",
    "outputId": "b5aa0e80-d7bb-4050-b810-634bbe3e8f6f"
   },
   "outputs": [],
   "source": [
    "# Visualize the formation energy data\n",
    "df_mp.formation_energy_per_atom.hist()\n",
    "plt.xlabel(\"formation energy per atom [eV]\")\n",
    "plt.ylabel(\"count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n9xrE7VXTzLw"
   },
   "source": [
    "Calculate the association rules using the apriori alogrithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KdYeMRG87jR9",
    "outputId": "36cad96f-9d8f-4e9e-bd16-248b9d63e359"
   },
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "if use_legacy_materials_project:\n",
    "  df = df.drop(columns=[\"elements\", \"task_id\", \"pretty_formula\", \"band_gap\", \"e_above_hull\", \"formation_energy_per_atom\"])\n",
    "else:\n",
    "  df = df.drop(columns=[\"elements\", \"material_id\", \"formula_pretty\", \"band_gap\", \"energy_above_hull\", \"formation_energy_per_atom\"])\n",
    "\n",
    "# Apply Apriori algorithm\n",
    "frequent_itemsets = apriori(df, min_support=0.05, use_colnames=True)\n",
    "\n",
    "# Generate association rules\n",
    "rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "id": "04b_cIr23QNC",
    "outputId": "b854d9e8-505f-45c1-f517-3e7ce73e524b"
   },
   "outputs": [],
   "source": [
    "select_rules_columns = ['antecedents', 'consequents',  'support', 'confidence', 'lift']\n",
    "rules.loc[:5,select_rules_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "hUNIhcf316Kw",
    "outputId": "f6c40d17-692b-4d1e-bbd6-c5f890432351"
   },
   "outputs": [],
   "source": [
    "# Display results for a set of criteria defined by the support and confidence\n",
    "support_criterion = rules.support > 0.11\n",
    "confidence_criterion = rules.confidence > 0.50\n",
    "rules[support_criterion & confidence_criterion][select_rules_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yW9PPaM5UUNM"
   },
   "source": [
    "### Question:\n",
    "- Can these results be easily interpreted?\n",
    "- What's a plausible interpretation?\n",
    "- What would you change to improve interpretability? [Hint: Consider the data distribution and the choice of descriptors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zMHUL6n9JVYG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V9_WZV0qU8ip"
   },
   "source": [
    "# Generative modeling\n",
    "- Leverage variational autoencoders (VAEs) from materials discovery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6_aUmIbmJa1k"
   },
   "source": [
    "Install Required Libraries to implement the VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o5CYGxjmJVfr",
    "outputId": "a8386bba-c96c-41d6-ccea-83ccdfba72d0"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install pymatgen pandas tensorflow keras numpy scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z0IpN1R5Je21"
   },
   "source": [
    " Fetch materials data from the Materials Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V98D5snm98TY"
   },
   "outputs": [],
   "source": [
    "# import useful modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 138,
     "referenced_widgets": [
      "42e1e112bf7b4b64a1a684211acf7143",
      "3132056c0ea64f528514c385ebcd730b",
      "0c5a7f5cef8042fb956bd886c61322eb",
      "6f9fea5f4cc14942b4c9f5018d136b25",
      "4cceb6887b5443b69d9e90267964e154",
      "013a28335c8945888c7e6cdb629f8180",
      "25f9ca315ffc477c946f274e90f45a3e",
      "f2fb171d37624fa0844583689a14b4c1",
      "6c16debc84064bbdb0e94a9400c445ec",
      "29582ae776904874a6a3b0f5559888fc",
      "7197bc7353d8433a8f435e70fb8dcfcb"
     ]
    },
    "id": "QC88RSveDVuS",
    "outputId": "50630625-7dbe-4711-d8cf-28756761b6d2"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Query oxide materials with band gap data and formation energy per atom data\n",
    "if use_legacy_materials_project:\n",
    "  materials_data_gm = mpr.query(\n",
    "      criteria={\"elements\": {\"$in\": [\"O\", \"Fe\", \"Ti\", \"Ni\", \"Zn\"]}},  # Example elements\n",
    "      properties=[\"pretty_formula\", \"elements\", \"formation_energy_per_atom\", \"band_gap\"]\n",
    "  )\n",
    "else:\n",
    "  print(\"use_legacy_materials_project:\", use_legacy_materials_project)\n",
    "  elements_list = [\"O\"]   # Elements to search for\n",
    "  all_materials = []\n",
    "  with MPRester(API_KEY) as mpr:\n",
    "      for element in elements_list:\n",
    "          materials = mpr.summary.search(\n",
    "              elements=[element],  # Get materials that contain at least this element\n",
    "              fields=[\"formula_pretty\", \"elements\", \"formation_energy_per_atom\", \"band_gap\"]\n",
    "          )\n",
    "          all_materials.extend(materials)  # Add to list\n",
    "\n",
    "materials_data_gm = all_materials\n",
    "# you can pickle the result and save to your google drive to reload data with ease.\n",
    "print(len(materials_data_gm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mweo7CJiXUzK"
   },
   "outputs": [],
   "source": [
    "# Convert to DataFrame\n",
    "\n",
    "fields_not_requested = ['builder_meta', 'nsites', 'nelements', 'composition', 'composition_reduced', 'formula_anonymous', 'chemsys', 'volume', 'density', 'density_atomic', 'symmetry', 'property_name', 'material_id', 'deprecated', 'deprecation_reasons', 'last_updated', 'origins', 'warnings', 'structure', 'task_ids', 'uncorrected_energy_per_atom', 'energy_per_atom', 'energy_above_hull', 'is_stable', 'equilibrium_reaction_energy_per_atom', 'decomposes_to', 'xas', 'grain_boundaries', 'cbm', 'vbm', 'efermi', 'is_gap_direct', 'is_metal', 'es_source_calc_id', 'bandstructure', 'dos', 'dos_energy_up', 'dos_energy_down', 'is_magnetic', 'ordering', 'total_magnetization', 'total_magnetization_normalized_vol', 'total_magnetization_normalized_formula_units', 'num_magnetic_sites', 'num_unique_magnetic_sites', 'types_of_magnetic_species', 'bulk_modulus', 'shear_modulus', 'universal_anisotropy', 'homogeneous_poisson', 'e_total', 'e_ionic', 'e_electronic', 'n', 'e_ij_max', 'weighted_surface_energy_EV_PER_ANG2', 'weighted_surface_energy', 'weighted_work_function', 'surface_anisotropy', 'shape_factor', 'has_reconstructed', 'possible_species', 'has_props', 'theoretical', 'database_IDs']\n",
    "if use_legacy_materials_project:\n",
    "  df = pd.DataFrame(materials_data_gm)\n",
    "else:\n",
    "  # Flatten each document before creating the DataFrame\n",
    "  flattened_docs_gm = [flatten_dict(doc.dict()) for doc in materials_data_gm]\n",
    "  df = pd.DataFrame(flattened_docs_gm)\n",
    "  df = df.drop(columns=fields_not_requested)\n",
    "  df_clean = df.dropna(axis=0)\n",
    "  df_clean = df_clean.drop(columns=\"fields_not_requested\")\n",
    "  df = df_clean.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "ED9Nfq1dXGRd",
    "outputId": "46d7e12a-224c-439a-a827-850300ffaad7"
   },
   "outputs": [],
   "source": [
    "# Inspect data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U4vqc9yZXs5K"
   },
   "source": [
    "####  Data wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hyija12mKGxW"
   },
   "outputs": [],
   "source": [
    "# Get a list of unique elements\n",
    "unique_elements = sorted(set(el for elems in df[\"elements\"] for el in elems))\n",
    "\n",
    "# One-hot encode elemental composition\n",
    "for element in unique_elements:\n",
    "    df[element] = df[\"elements\"].apply(lambda x: 1 if element in x else 0)\n",
    "\n",
    "# Normalize formation energy\n",
    "scaler = StandardScaler()\n",
    "df[\"formation_energy_per_atom\"] = scaler.fit_transform(df[[\"formation_energy_per_atom\"]])\n",
    "\n",
    "# Drop unused columns\n",
    "if use_legacy_materials_project:\n",
    "  df = df.drop(columns=[\"elements\", \"pretty_formula\"])\n",
    "else:\n",
    "  df = df.drop(columns=[\"elements\", \"formula_pretty\"])\n",
    "\n",
    "df_X = df.copy()\n",
    "df_X = df_X.drop(columns=[\"formation_energy_per_atom\",\"band_gap\"])\n",
    "\n",
    "# Convert to NumPy array for training\n",
    "X = df_X.to_numpy()\n",
    "\n",
    "# Normalize data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tptn26bhbrBs"
   },
   "source": [
    "What do the data look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "EhqjwObEbvEV",
    "outputId": "c5edefa6-c4b4-45c2-a2d9-4aaf0aaa43d9"
   },
   "outputs": [],
   "source": [
    "df_X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hqSGVLI0JqKQ"
   },
   "source": [
    "### Build the Variational Autoencoder (VAE)\n",
    " A VAE consists of:\n",
    "\n",
    "- Encoder: Maps input materials to a latent space.\n",
    "- Latent Space: Compressed, (hopefully) meaningful representation of materials.\n",
    "- Decoder: Generates new material compositions from the latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 557
    },
    "id": "G0HALrJKJxYj",
    "outputId": "f09ecaa2-eb90-4bdf-d6ef-8c527fb736d3"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Define dimensions\n",
    "input_dim = X.shape[1]\n",
    "latent_dim = 5  # Size of the compressed representation\n",
    "\n",
    "# Encoder\n",
    "inputs = keras.Input(shape=(input_dim,))\n",
    "h = layers.Dense(32, activation=\"relu\")(inputs)\n",
    "z_mean = layers.Dense(latent_dim)(h)\n",
    "z_log_var = layers.Dense(latent_dim)(h)\n",
    "\n",
    "# Sampling function\n",
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    batch = tf.shape(z_mean)[0]\n",
    "    dim = tf.shape(z_mean)[1]\n",
    "    epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "    return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "z = layers.Lambda(sampling)([z_mean, z_log_var])\n",
    "\n",
    "# Encoder\n",
    "encoder = keras.Model(inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
    "encoder.summary()\n",
    "\n",
    "# Decoder\n",
    "latent_inputs = keras.Input(shape=(latent_dim,))\n",
    "x = layers.Dense(32, activation=\"relu\")(latent_inputs)\n",
    "x = layers.Dense(64, activation=\"relu\")(x)\n",
    "outputs = layers.Dense(X_scaled.shape[1], activation=\"linear\")(x)\n",
    "\n",
    "decoder = keras.Model(latent_inputs, outputs, name=\"decoder\")\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q6nx4rvWYOGJ"
   },
   "source": [
    "How can you vary your architecture to improve your results? Consider the following:\n",
    "- The input to the model\n",
    "- The size of the latent space\n",
    "- The number of hidden layers\n",
    "- The activation functions\n",
    "- Other hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IJt_1usEvw4H",
    "outputId": "431fba0a-1ffd-4214-fd2b-5424efd1957c"
   },
   "outputs": [],
   "source": [
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var, z = self.encoder(inputs)\n",
    "        reconstructed = self.decoder(z)\n",
    "        return reconstructed\n",
    "\n",
    "# Initialize VAE\n",
    "vae = VAE(encoder, decoder)\n",
    "\n",
    "# Define loss function\n",
    "mse_loss_fn = keras.losses.MeanSquaredError()\n",
    "\n",
    "def vae_loss(y_true, y_pred):\n",
    "    z_mean, z_log_var, _ = encoder(y_true)\n",
    "    mse = mse_loss_fn(y_true, y_pred)\n",
    "    kl_loss = -0.5 * tf.reduce_mean(1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "    return mse + kl_loss\n",
    "\n",
    "# Compile the model\n",
    "vae.compile(optimizer=keras.optimizers.Adam(), loss=vae_loss)\n",
    "\n",
    "# Train the VAE\n",
    "vae.fit(X_scaled, X_scaled, epochs=5, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XoJJ0116bNSX"
   },
   "source": [
    "Generate New Materials\n",
    "- Once the VAE is trained, we can sample new materials from the latent space.\n",
    "- Are the results easily interpretable? How can we modify the process or the ML input to overcome challenges linked to interpretability?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 273
    },
    "id": "aMIHBzsMvAmY",
    "outputId": "19452499-2476-4fe0-afb1-5fb37eacf33a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Sample from latent space\n",
    "num_new_samples = 10\n",
    "z_new = np.random.normal(size=(num_new_samples, latent_dim))\n",
    "\n",
    "# Decode to material representations\n",
    "generated_materials = decoder.predict(z_new)\n",
    "\n",
    "# Convert back to original scale\n",
    "generated_materials = scaler.inverse_transform(generated_materials)\n",
    "\n",
    "# Display generated features\n",
    "pd.DataFrame(generated_materials, columns=df_X.columns).head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4lM6q_TmKB03"
   },
   "source": [
    "Interpretation of Generated Materials\n",
    "- Each row represents a synthetic material composition.\n",
    "- The values for each element indicate its presence in the new material.\n",
    "- Formation energy per atom provides an estimate of material stability.\n",
    "\n",
    "## Question:\n",
    "- How do we select for interesting materials? How do we define interesting?\n",
    "- What are some challenges with this representation that need to be overcome to be able to implement a framework for materials design?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QxoUMBRxKFR0"
   },
   "source": [
    "## Visualizing the Latent Space of the VAE\n",
    "\n",
    "- Visualizing the latent space helps us understand how the VAE encodes materials and how different materials are related.\n",
    "\n",
    "- We reduce the latent space to 2D using PCA.\n",
    "- Plot materials in the latent space to see clusters of similar compositions.\n",
    "- Color-code materials by their formation energy to observe trends.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yZzfnCRaKNUZ"
   },
   "source": [
    "Use t-SNE to Visualize Latent Representations\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ybrnTEhmKGSt",
    "outputId": "e8994fc7-6407-4153-fb52-cb81c8b4a35b"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "run_full_space = False  #takes a long time to calculate all the rows\n",
    "\n",
    "if run_full_space:\n",
    "  # Encode materials into latent space\n",
    "  z_mean, _, _ = encoder.predict(X_scaled)\n",
    "\n",
    "  # Apply t-SNE to reduce dimensionality to 2D\n",
    "  tsne = TSNE(n_components=2, perplexity=30, random_state=42)\n",
    "  z_2d = tsne.fit_transform(z_mean)\n",
    "else:\n",
    "  # Encode materials into latent space\n",
    "  z_mean, _, _ = encoder.predict(X_scaled)\n",
    "  # Apply t-SNE to reduce dimensionality to 2D\n",
    "  tsne = TSNE(n_components=2, perplexity=30, random_state=42)\n",
    "  subset_data = 100\n",
    "  z_2d = tsne.fit_transform(z_mean[:subset_data,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "vkjMFbvnOQqV",
    "outputId": "c924c4a0-2a17-4735-a85f-7704fa9475ff"
   },
   "outputs": [],
   "source": [
    "# Convert to DataFrame\n",
    "df_latent = pd.DataFrame(z_2d, columns=[\"Latent_X\", \"Latent_Y\"])\n",
    "df_latent[\"formation_energy_per_atom\"] = df[\"formation_energy_per_atom\"]  # Add formation energy info for coloring\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# plt.figure(figsize=(10, 6))\n",
    "scatter = sns.scatterplot(x=\"Latent_X\", y=\"Latent_Y\", hue=\"formation_energy_per_atom\", palette=\"viridis\", data=df_latent, legend=False)\n",
    "\n",
    "c = df_latent[\"formation_energy_per_atom\"]\n",
    "norm = plt.Normalize(vmin=min(c), vmax=max(c))\n",
    "sm = plt.cm.ScalarMappable(cmap=\"viridis\", norm=norm)\n",
    "sm.set_array([])  # Only needed for colorbar\n",
    "cbar = plt.colorbar(sm, ax=ax)\n",
    "cbar.set_label(\"formation energy\")\n",
    "\n",
    "#plt.colorbar(label=\"Band Gap (eV)\")\n",
    "plt.title(\"t-SNE Visualization of the VAE Latent Space\")\n",
    "plt.xlabel(\"Latent Dimension 1\")\n",
    "plt.ylabel(\"Latent Dimension 2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XTUognFtfkIR"
   },
   "outputs": [],
   "source": [
    "visualize_formation_energy_data = False\n",
    "if visualize_formation_energy_data:\n",
    "  df_latent.formation_energy_per_atom.hist()\n",
    "  plt.xlabel(\"formation energy per atom [eV]\")\n",
    "  plt.ylabel(\"count\")\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DZz58vpuKRP2"
   },
   "source": [
    "Use PCA to Visualize the Latent Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "mmAU8HcLKUmN",
    "outputId": "480f6405-4ca8-4c4c-81f7-ba70c36bc8a5"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Reduce latent space to 2D using PCA\n",
    "pca = PCA(n_components=2)\n",
    "z_pca = pca.fit_transform(z_mean)\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_pca = pd.DataFrame(z_pca, columns=[\"PC1\", \"PC2\"])\n",
    "df_pca[\"formation_energy_per_atom\"] = df[\"formation_energy_per_atom\"]\n",
    "\n",
    "# Plot PCA latent space\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=\"PC1\", y=\"PC2\", hue=\"formation_energy_per_atom\", palette=\"coolwarm\", data=df_pca)\n",
    "#plt.colorbar(label=\"formation_energy_per_atom (eV)\")\n",
    "plt.title(\"PCA Projection of the VAE Latent Space\")\n",
    "plt.xlabel(\"Principal Component 1\")\n",
    "plt.ylabel(\"Principal Component 2\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "clKzrF8dKX3t"
   },
   "source": [
    "Interpretation of the Visualization\n",
    "- Clusters: Similar materials should cluster together.\n",
    "- Formation Energy Trends: If formation energy correlates with latent space structure, we might find regions of stable/unstable materials.\n",
    "- Outliers: These could be unusual materials with unique properties."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_4vT0gB0gkHz"
   },
   "source": [
    "--------------------------------------------------------------------------------\n",
    "# Research Challenge: vdW magnet informatics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uA0BEyjrteQI"
   },
   "source": [
    "### Download 2D magnetic materials formation energies data set:\n",
    "\n",
    "Download data from :\n",
    "https://archive.materialscloud.org/record/2019.0020/v1\n",
    "\n",
    "Description of data and corresponding study can be found here:\n",
    "https://www.nature.com/articles/s41598-020-72811-z\n",
    "\n",
    "- save the file to your google drive (with colab) or your local drive (jupyter notebook).\n",
    "- Can also upload from github: https://github.com/quantum-intelligence/materials-informatics-tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X7eDJn48KRdM"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PZjN7YaYtgQw",
    "outputId": "110320c0-b9f4-4433-e5ae-f18e63953cd6"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c8npT9E5zTKo",
    "outputId": "004f5e48-0691-4d70-c91b-f2adfa666037"
   },
   "outputs": [],
   "source": [
    "ls drive/MyDrive/GDS_Tutorial_2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fZCTUuJ-tosE"
   },
   "source": [
    "Open and load \"magneticmoment_Ef_data.csv\" using pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2erYtY4_tsm9"
   },
   "outputs": [],
   "source": [
    "# Create dataframe of \"CGT_materials_data.csv\" using pandas.\n",
    "# Change the path to CGT_materials_data.csv as needed.\n",
    "data_path = \"drive/MyDrive/GDS_Tutorial_2025/CGT_materials_data.csv\"\n",
    "df = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gwaDGI-PtvSU"
   },
   "source": [
    "Explore the pandas object by examinging the columns:\n",
    "- df.column()\n",
    "\n",
    "A summary of the dataframe:\n",
    "- df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 470
    },
    "id": "L-B2u5Rkt0rb",
    "outputId": "4c7ba9cf-cf44-4fd5-98cc-c8f521ad2b22"
   },
   "outputs": [],
   "source": [
    "df.head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bHvDEtyVcRC_"
   },
   "source": [
    "###Task 0\n",
    "- What are all the possible targets (materials properties) in the dataset?\n",
    "- What are the 'easy to use' materials descriptors in the dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2YXi025ft5w7"
   },
   "source": [
    "Consider the following target property, y and descriptors, X.\n",
    "\n",
    "y --> 'formation_energy'\n",
    "\n",
    "X --> 'std_ion', 'nvalence_avg', 'dipole_max_dif', 'dipole_std_dif','atomic_vol_max_dif','atomic_rad_max_dif'\n",
    "\n",
    "- Create X and y data\n",
    "- Perform data visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gWqrXMiouEgu"
   },
   "source": [
    "### Data visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DFm8Xsg4cfjs"
   },
   "source": [
    "###Task #1:\n",
    "- Identify patterns in the data by using data visualization (PCA, tSNE, K-means clustering).\n",
    "- What is an appropriate goal for this study? What property can be partitioned into classes? The formation energy? The magneic moment? Or the magnetic order?\n",
    "- What are appropriate materials descriptors if your goal is to investigate the above target property? [HINT: see descriptors used in the sci reports paper or use your physical intuition'\n",
    "- Visualize the results using PCA, tSNE and K-means clustering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6eQF3fQ2crT-"
   },
   "source": [
    "tSNE visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "ZHmOQzFcuA27",
    "outputId": "5b6c206c-230c-43cf-f6d3-e7181ccd4d5a"
   },
   "outputs": [],
   "source": [
    "# Visualize your data before attempting model fitting:\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "X = df[['std_ion', 'nvalence_avg', 'dipole_max_dif', 'dipole_std_dif','atomic_vol_max_dif','atomic_rad_max_dif']]\n",
    "y = df['formation_energy']\n",
    "\n",
    "# Apply t-SNE to reduce dimensionality to 2D\n",
    "tsne = TSNE(n_components=2, perplexity=30, random_state=42)\n",
    "X_2d = tsne.fit_transform(X)\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_tsne = pd.DataFrame(X_2d, columns=[\"X_1\", \"X_2\"])\n",
    "df_tsne[\"formation_energy\"] = df[\"formation_energy\"]  # Add band gap info for coloring\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=\"X_1\", y=\"X_2\", hue=\"formation_energy\", palette=\"viridis\", data=df_tsne)\n",
    "# plt.colorbar(label=\"formation_energy (eV)\")\n",
    "plt.title(\"t-SNE Visualization of the CGT chemical space\")\n",
    "plt.xlabel(\"tSNE Dimension 1\")\n",
    "plt.ylabel(\"tSNE Dimension 2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UUiKY99tPX28"
   },
   "source": [
    "PCA visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "DurdSTyRPXEe",
    "outputId": "6444df65-e69b-4993-a333-654857fa1f76"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Reduce latent space to 2D using PCA\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_pca = pd.DataFrame(X_pca, columns=[\"PC1\", \"PC2\"])\n",
    "df_pca[\"formation_energy\"] = df[\"formation_energy\"]\n",
    "\n",
    "# Plot PCA latent space\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=\"PC1\", y=\"PC2\", hue=\"formation_energy\", palette=\"coolwarm\", data=df_pca)\n",
    "# plt.colorbar(label=\"formation energy (eV)\")\n",
    "plt.title(\"PCA Projection of the CGT Chemical Space\")\n",
    "plt.xlabel(\"Principal Component 1\")\n",
    "plt.ylabel(\"Principal Component 2\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WTTksyFKcz_L"
   },
   "source": [
    "### PCA with new target property\n",
    "- choose descriptors to suit target\n",
    "- create a visualization and color markers with target property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0YdkN2u8c0R8"
   },
   "outputs": [],
   "source": [
    "# insert your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C8wkPnjRc8ww"
   },
   "source": [
    "###tSNE with new target proerty\n",
    "- choose descriptors to suit target\n",
    "- create a visualization and color markers with target property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ja7Vm008c9qX"
   },
   "outputs": [],
   "source": [
    "# insert your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hWdYobNOc-Oa"
   },
   "source": [
    "### Clustering the CGT dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 569
    },
    "id": "TWgjfKbr0W0T",
    "outputId": "54e186b4-eb87-4840-bb24-29ebe81c32c0"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "n_clusters = 2 # Is the an appropriate number of clusters for your research goals?\n",
    "random_state = 42\n",
    "\n",
    "# Perform K-Means clustering\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=random_state, n_init=10)\n",
    "kmeans.fit(X)\n",
    "y_pred = kmeans.labels_\n",
    "\n",
    "# Plot the clusters\n",
    "plt.figure(figsize=(8, 6))\n",
    "# Make arbitratry 2d projection on X for visualization\n",
    "# Consider implementing a better approach to X.iloc[:,0] and X.iloc[:,1]\n",
    "plt.scatter(X.iloc[:, 0], X.iloc[:, 1], c=y_pred, cmap='viridis', edgecolors='k', alpha=0.6)\n",
    "plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1],\n",
    "            s=200, c='red', marker='X', edgecolors='black', label=\"Centroids\")\n",
    "\n",
    "plt.title(\"K-Means Clustering on CrGeTe$_3$ Data\")\n",
    "plt.xlabel(\"X$_1$\")\n",
    "plt.ylabel(\"X$_2$\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FPcEgM2bNt0Q"
   },
   "source": [
    "### Question\n",
    "- Do the clusters correspond to some physically releveant quantity?\n",
    "- How can we check our hypothesis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5uRK3p-jN9u_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qs5iApM8dHVs"
   },
   "source": [
    "If time permits (and later at home) explore the following for this Cr$_2$Ge$_2$Te$_6$ dataset:\n",
    "- Associative rule learning\n",
    "- Generative modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oVrHefu_dHiN"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
